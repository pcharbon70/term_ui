# Feature Plan: 4.3 Layout Cache

## Problem Statement

Layout solving is computationally expensive and occurs frequently (every frame, every resize). Without caching:
- Same layouts are recalculated repeatedly
- Performance degrades with complex constraint sets
- CPU usage increases unnecessarily
- Frame rate may drop during intensive rendering

The layout cache provides O(1) lookup for unchanged layouts, dramatically improving performance.

## Solution Overview

Implement an ETS-based layout cache with LRU eviction:
- **ETS storage** - fast concurrent access
- **Constraint hashing** - efficient key comparison
- **LRU eviction** - bounded memory usage
- **Transparent integration** - callers don't know if result is cached

### Key Design Decisions

- **ETS for performance** - concurrent reads without process bottleneck
- **Hash-based keys** - fast lookup without deep comparison
- **Access time tracking** - enable LRU eviction
- **Configurable limits** - tune for memory/hit-rate tradeoff

## Technical Details

### File Structure

```
lib/term_ui/layout/
├── constraint.ex           # Constraint types (completed)
├── solver.ex               # Constraint solver (completed)
└── cache.ex                # Layout cache

test/term_ui/layout/
├── constraint_test.exs     # (completed)
├── solver_test.exs         # (completed)
└── cache_test.exs          # Cache tests
```

### Dependencies

- Section 4.2 Constraint Solver (completed)
- ETS for storage
- Will be used by Container components

## Implementation Plan

### Task 4.3.1: Cache Structure

ETS table structure for storing layout results.

- [x] 4.3.1.1 Implement cache ETS table with key `{constraints_hash, width, height}`
- [x] 4.3.1.2 Implement value structure `{solved_rects, access_time}`
- [x] 4.3.1.3 Implement cache statistics: size, hit count, miss count
- [x] 4.3.1.4 Implement constraint hashing for efficient key comparison

### Task 4.3.2: Cache Operations

Basic cache operations: lookup, insert, invalidate.

- [x] 4.3.2.1 Implement `cache_lookup/3` returning cached result or nil
- [x] 4.3.2.2 Implement `cache_insert/4` storing result and updating access time
- [x] 4.3.2.3 Implement `cache_invalidate/1` removing specific entry
- [x] 4.3.2.4 Implement `cache_clear/0` removing all entries

### Task 4.3.3: LRU Eviction

Remove least-recently-used entries when cache exceeds limit.

- [x] 4.3.3.1 Implement size limit configuration (default 500 entries)
- [x] 4.3.3.2 Implement access time tracking updated on each lookup
- [x] 4.3.3.3 Implement eviction pass removing oldest entries when over limit
- [x] 4.3.3.4 Implement eviction scheduling running on insert

### Task 4.3.4: Cache Integration

Wrap solver with automatic caching.

- [x] 4.3.4.1 Implement `Layout.solve/3` with automatic caching
- [x] 4.3.4.2 Implement cache-through pattern checking cache then solving
- [x] 4.3.4.3 Implement uncached solver access for testing
- [x] 4.3.4.4 Implement cache warming for predictable initial performance

### Unit Tests

- [x] Test cache lookup returns stored results
- [x] Test cache insert stores and retrieves correctly
- [x] Test cache miss returns nil and triggers solve
- [x] Test LRU eviction removes oldest entries
- [x] Test cache size stays within limit
- [x] Test invalidation removes specific entries
- [x] Test clear removes all entries
- [x] Test cache integration uses cache transparently
- [x] Test cache statistics are accurate

## Success Criteria

1. Cache provides O(1) lookup for cached layouts
2. LRU eviction keeps memory bounded
3. Statistics track hit rate accurately
4. Integration is transparent to callers
5. All unit tests pass

## Current Status

**Status**: Complete

### How to Run
```bash
mix test test/term_ui/layout/cache_test.exs
```

## Notes

### Cache Key Design

```elixir
# Key: {constraints_hash, width, height}
# - constraints_hash: :erlang.phash2 of constraint list
# - width/height: dimensions for the solve

key = {:erlang.phash2(constraints), width, height}
```

### ETS Table Structure

```elixir
# Table: :term_ui_layout_cache
# Type: :set
# Access: :public (concurrent reads)

# Entry format:
# {key, {result, access_time, insert_time}}
```

### Example Usage

```elixir
alias TermUI.Layout.Cache

# Start cache (typically in application supervision tree)
Cache.start_link(max_size: 1000)

# Cached solve
result = Cache.solve(constraints, %{x: 0, y: 0, width: 100, height: 50})

# Get statistics
stats = Cache.stats()
# => %{size: 150, hits: 1234, misses: 56, hit_rate: 0.956}

# Clear on resize
Cache.clear()
```
